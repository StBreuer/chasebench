{
  "name": "Chasebench",
  "tagline": "",
  "body": "## Tested Systems\r\nOur main goals are to determine whether available chase implementations can support data exchange and query answering in absolute terms, and to investigate the implementation decisions that are most rele- vant to performance. To answer these questions, we identified nine publicly available chase implementations.\r\n\r\n#### Chase for data exchange\r\n- **CHASEFUN** - _A. Bonifati, I. Ileana, and M. Linardi. Functional Dependencies Unleashed for Scalable Data Exchange. In SSDBM, 2016_\r\n- **DEMO** (Data Exchange Modelling) _R. Pichler and V. Savenkov. DEMo: Data Exchange Modeling Tool. PVLDB, 2(2):1606–1609, 2009_\r\n- **LLUNATIC** - _F. Geerts, G. Mecca, P. Papotti, and D. Santoro. That’s all folks! LLUNATIC goes open source. PVLDB, 7(13):1565–1568, 2014_ \r\n\r\n#### Chase for query reformulation\r\n- **PDQ** - _M. Benedikt, J. Leblay, and E. Tsamoura. Querying\r\nwith access patterns and integrity constraints. In\r\nVLDB, 2015_\r\n- **PEGASUS** - _M. Meier. The backchase revisited. VLDB J., 23(3):495–516, 2014_\r\n\r\n#### Chase for query answering\r\n- **GRAAL** - _J.-F. Baget, M. Leclère, M.-L. Mugnier, S. Rocher,\r\nand C. Sipieter. Graal: A toolkit for query answering\r\nwith existential rules. In RuleML, 2015_\r\n\r\n#### Chase-related tools\r\n- **DLV** - _N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob, S. Perri, and F. Scarcello. The DLV system for knowledge representation and reasoning. TOCL, 7(3):499–562, 2006_\r\n- **E** - _The E theorem prover. http://wwwlehre.dhbw-stuttgart.de/ sschulz/E/E.html_\r\n- **RDFOX** - _B. Motik, Y. Nenov, R. Piro, I. Horrocks, and D. Olteanu. Parallel Materialisation of Datalog Programs in Centralised, Main-Memory RDF Systems. In AAAI, 2014_\r\n\r\n\r\n\r\n\r\n<img width=550 src=\"https://www.dropbox.com/s/ydvq5ngdm6d8wob/test-tools.png?dl=1\"/>\r\n\r\n## Test Scenarios\r\nOur benchmark consists of a total of 23 scenarios, each scenario consisting of source and target schemas, constraints, queries, and source data. The scenarios belong to 5 different families, detailed in Table 2. The first one includes 6 small scenarios used as correctness tests for data exchange. The others were used for performance testing, both in data ex- change and query evaluation, and for correctness tests based on query results. Two of these, IBENCH and LUBM, are based on known standards, either from the database or the Semantic Web community. The other two, MANUALLY CURATED and DEEP, we developed ourselves in order to test specific aspects of the chase.\r\n\r\n<img width=650 src=\"https://www.dropbox.com/s/lweb4v3wrk9o02d/test-scenarios.png?dl=1\"/>\r\n\r\n## Other Tools\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}